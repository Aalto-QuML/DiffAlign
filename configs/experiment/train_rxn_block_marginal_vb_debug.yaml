# @package _global_
general:
  project: 'retrodiffuser' # for wandb logging
  name: 'rxn-block-marginal-vb-debug'
  task: 'rxn'
diffusion: 
  transition: 'absorbing_masknoedge'
  denoiser: 'neuralnet'
  edge_conditional_set: 'val' # This is used for other stuff as well now than edge conditional 
  diffuse_edges: True
  diffuse_nodes: True
  classifier_free_guidance: True
  classifier_free_uncond_prob: 0.1
  classifier_free_guidance_weight: 0.1
  diffusion_noise_schedule: 'cosine'
  diffusion_steps: 5
  lambda_train: [1, 0]
  ce_lambda: 0.01 # used with loss vb+ce
  extra_features: null
  mask_nodes: 'atom_mapping' # sn, reactant, product_and_sn, reactant_and_sn, first_n, ring
  mask_edges: 'atom_mapping'
  node_states_to_mask: ['SuNo', 'none']
  edge_states_to_mask: ['mol', 'within', 'across']
neuralnet:
  increase_y_dim_for_multigpu: False
  use_ema: False
  ema_decay: 0.999
  checkpoint_file: null
  architecture: 'with_y' #'with_y_pos_enc'
  n_layers: 2
  # hidden_mlp_dims: {'X': 256, 'E': 128, 'y': 128}
  # hidden_dims : {'dx': 256, 'de': 64, 'dy': 64, 'n_head': 8, 
  #                'dim_ffX': 256, 'dim_ffE': 128, 'dim_ffy': 128}
  # hidden_dims : {'dx': 32, 'de': 1, 'dy': 1, 'n_head': 1, 'dim_ffX': 16, 'dim_ffE': 1, 'dim_ffy': 1}
  # hidden_mlp_dims: {'X': 16, 'E': 1,'y': 1}
  hidden_dims : {'dx': 16, 'de': 8, 'dy': 8, 'n_head': 2, 'dim_ffX': 16, 'dim_ffE': 8, 'dim_ffy': 8}
  hidden_mlp_dims: {'X': 16, 'E': 8,'y': 8}
  extra_features: True
  pos_encoding_type: 'smiles_pos_enc' # laplacian_pos_enc, smiles_pos_enc, infoleak_pos_enc
dataset:
  name: uspto-50k
  dataset_nb: 'dummy10' #'1'
  num_workers: 0
  shuffle: True
  nb_rct_dummy_nodes: 10
  with_explicit_h: False
  with_formal_charge: True
  batchsize_bins: {'train': [120, 56, 16, 8], 'test': [64], 'val': [64]}
  size_bins: {'train': [64, 83, 102, 140], 'test': [250],'val': [250]}
train:
  with_mask: False
  seed: 1
  loss: 'vb'
  epochs: 4
  lr: 1e-3
  batch_size: 32
  batch_by_size: True
  log_to_wandb: False
  log_grad: False
  grad_every_step: 100
  eval_every_epoch: 2
  log_every_t: 2
  chains_to_save: 2
  samples_to_generate: 2
test:
  testfile: 0
  repeat_elbo: 1
  loss_0_repeat: 4
  elbo_samples: 2
  full_dataset: False
  plot_dummy_nodes: True
  n_conditions: 2 # total number of samples from the test set
  batch_size: 2 # size of batch to iterate over when ELBO evaluation
  n_samples_per_condition: 2 # size of batch to iterate over when sampling based on different conditionings
  rep_samples_per_condition: 1 # max samples to generate for each condition (for memory reasons)
  smiles_accuracy: True
  size_test_splits: 100
  with_denoising: True
  wandb_log_samples: True
  topks: [1,3,5,10,50,100]
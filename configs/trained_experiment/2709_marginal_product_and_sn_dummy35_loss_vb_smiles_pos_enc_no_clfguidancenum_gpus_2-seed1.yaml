# @package _global_
dataset:
  add_supernode_edges: true
  batchsize_bins:
    test:
    - 64
    train:
    - 240
    - 112
    - 32
    - 16
    val:
    - 64
  canonicalize_molecule: true
  datadir: data/uspto-50k
  datadist_dir: data/uspto-50k
  dataset: uspto-50k
  dataset_nb: block-35
  name: uspto-50k
  nb_rct_dummy_nodes: 35
  num_workers: 0
  pin_memory: false
  remove_h: false
  shuffle: true
  size_bins:
    test:
    - 250
    train:
    - 64
    - 83
    - 102
    - 140
    val:
    - 250
  with_explicit_h: false
  with_formal_charge: true
diffusion:
  ce_lambda: 0.01
  classifier_free_full_unconditioning: false
  classifier_free_guidance: false
  classifier_free_guidance_weight: 0.1
  classifier_free_uncond_prob: 0.1
  denoiser: neuralnet
  diffuse_edges: true
  diffuse_nodes: true
  diffusion_noise_schedule: cosine
  diffusion_steps: 100
  edge_conditional_set: val
  edge_states_to_mask:
  - mol
  - within
  - across
  extra_features: null
  lambda_train:
  - 1
  - 0
  mask_edges: product_and_sn
  mask_nodes: product_and_sn
  node_states_to_mask:
  - SuNo
  - none
  num_node_steps: 1
  temperature_scaling_edge: 1
  temperature_scaling_node: 1
  transition: marginal
general:
  config_from_wandb: 2709_marginal_product_and_sn_dummy35_loss_vb_smiles_pos_enc_no_clfguidancenum_gpus_2-seed1
  gpus: 1
  log_every_steps: 50
  name: rxn_marginal_product_and_sn_dummy35_loss_vb_smiles_pos_enc_no_clfguidancenum_gpus_2-seed1
  project: retrodiffuser
  task: rxn
  wandb: online
  wandb_id: ''
  wandb_resume: false
  wandb_team: najwalb
neuralnet:
  architecture: with_y_atommap_number_pos_enc
  atom_map_pos_encoding: false
  checkpoint_file: null
  ema_decay: 0.999
  extra_features: true
  hidden_dims:
    de: 64
    dim_ffE: 128
    dim_ffX: 256
    dim_ffy: 128
    dx: 256
    dy: 64
    n_head: 8
  hidden_mlp_dims:
    E: 128
    X: 256
    y: 128
  increase_y_dim_for_multigpu: true
  load_checkpoint: false
  n_layers: 9
  pos_emb_permutations: 0
  pos_encoding_type: smiles_pos_enc
  use_all_gpus: true
  use_ema: false
test:
  batch_size: 32
  elbo_samples: 32
  eval_on_first_epoch: false
  full_dataset: false
  loss_0_repeat: 100
  n_conditions: 8
  n_samples: 1024
  n_samples_per_condition: 100
  plot_dummy_nodes: false
  rep_samples_per_condition: 1
  repeat_elbo: 1
  size_test_splits: 100
  smiles_accuracy: true
  testfile: 0
  topks:
  - 1
  - 3
  - 5
  - 10
  - 50
  - 100
  wandb_log_samples: true
  with_denoising: true
train:
  amsgrad: true
  batch_by_size: true
  batch_size: 110
  best_model_criterion: top-5
  chains_to_save: 4
  clip_grad: null
  ema_decay: 0
  epochs: 1000
  eval_every_epoch: 20
  grad_every_step: 100
  log_every_t: 2
  log_grad: false
  log_to_wandb: true
  loss: vb
  lr: 0.0002
  num_workers: 0
  optimizer: adamw
  overfit: falsesac
  progress_bar: false
  samples_to_generate: 4
  save_every_epoch: false
  save_model: true
  save_models_at_all: true
  seed: 1
  weight_decay: 1.0e-12
  with_mask: false
